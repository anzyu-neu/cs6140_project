{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42c639ce-5a69-469d-bdbe-a5c94c099c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c14553f-241f-4077-b44e-f1c24ce22fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2024-25 odds\n",
    "season_odds_24 = pd.read_csv(\"data_generation/2024-25_odds_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30c3b103-63f1-4bd1-bc42-2ebe86ddf9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stats\n",
    "#season_20 = pd.read_csv('data_generation/output_data/2020-21_data.csv')\n",
    "#season_21 = pd.read_csv('data_generation/output_data/2021-22_data.csv')\n",
    "season_22 = pd.read_csv('data_generation/output_data/2022-23_data.csv')\n",
    "season_23 = pd.read_csv('data_generation/output_data/2023-24_data.csv')\n",
    "season_24 = pd.read_csv('data_generation/output_data/2024-25_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d969a82-6ab7-4989-a2a0-79b5086b8318",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b338779-b5d3-485c-a708-2d8605e4149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combind and clean\n",
    "combined_seasons = pd.concat([season_22, season_23], ignore_index=True)\n",
    "combined_seasons = combined_seasons.drop_duplicates()\n",
    "combined_seasons = combined_seasons.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "361f18ee-3b70-4478-88dd-550b8bea24bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and target\n",
    "input = combined_seasons.drop(columns=['PTS'])\n",
    "target = combined_seasons['PTS']\n",
    "\n",
    "# Selected features for model training\n",
    "spearman_corr = pd.read_csv('data_generation/output_data/spearman_corr_features.csv')\n",
    "selected_features = spearman_corr['Feature'].tolist()\n",
    "\n",
    "existing_features = [feature for feature in selected_features if feature in input.columns] # check no mismatching features\n",
    "\n",
    "input = combined_seasons[existing_features]\n",
    "input = input.dropna(axis=1)\n",
    "\n",
    "# Split into train and test set\n",
    "input_train, input_test, target_train, target_test = train_test_split(input, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4868187-d549-4971-bd99-254689f037ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Cross-Validation R2 Score: 0.3967263888294036\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Search space of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# GridSearch\n",
    "rf_cv = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='r2',n_jobs=-1)\n",
    "rf_cv.fit(input_train, target_train)\n",
    "\n",
    "# Output best lambda and score\n",
    "print(\"Best Parameters:\", rf_cv.best_params_)\n",
    "print(\"Best Cross-Validation R2 Score:\", rf_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f114d08f-84d5-424d-9b9c-193cda79c237",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "494c6ddc-b0d5-44ff-b157-68032582f764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (MSE): 87.25829001202962\n",
      "Test MAE: 7.437235888885815\n",
      "\n",
      "Sample Predictions (PTS): [110.99723561 116.56484001 112.90907053 111.40591937 120.16453986\n",
      " 105.00706334 124.90042361 122.51938925 117.75574344 109.21524459]\n",
      "Actual Values (PTS): [119 106 130 106 108 106 118 115 109 101]\n",
      "\n",
      "--- Regression Metrics ---\n",
      "Test Loss (MSE from model): 87.26\n",
      "Test MAE (from model): 7.44\n",
      "Mean Squared Error (MSE): 87.26\n",
      "Root Mean Squared Error (RMSE): 9.34\n",
      "R-Squared (R²): 0.41\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    max_depth=20,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=200\n",
    ")\n",
    "\n",
    "rf.fit(input_train, target_train)\n",
    "\n",
    "test_loss = mean_squared_error(target_test, rf.predict(input_test))\n",
    "test_mae = mean_absolute_error(target_test, rf.predict(input_test))\n",
    "print(f\"Test Loss (MSE): {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "\n",
    "# Target prediction\n",
    "sample_predictions = rf.predict(input_test)\n",
    "print(\"\\nSample Predictions (PTS):\", sample_predictions[:10])\n",
    "print(\"Actual Values (PTS):\", target_test[:10].values)\n",
    "\n",
    "mse = mean_squared_error(target_test, sample_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(target_test, sample_predictions)\n",
    "\n",
    "print(\"\\n--- Regression Metrics ---\")\n",
    "print(f\"Test Loss (MSE from model): {test_loss:.2f}\")\n",
    "print(f\"Test MAE (from model): {test_mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-Squared (R²): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55e1702e-d259-441c-98ef-2b73bc8a18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(features, importances):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importances\n",
    "    })\n",
    "    return importance_df.sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "rf_importance = rf.feature_importances_\n",
    "importance_df = get_feature_importance(input_train.columns, rf_importance)\n",
    "importance_df.to_csv('rf_feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56642fb1-a5b4-4c41-b162-03bdfe87f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAM_CITY_ABBREVIATIONS = {\n",
    "    1610612737: \"ATL\",\n",
    "    1610612738: \"BOS\",\n",
    "    1610612739: \"CLE\",\n",
    "    1610612740: \"NOP\",\n",
    "    1610612741: \"CHI\",\n",
    "    1610612742: \"DAL\",\n",
    "    1610612743: \"DEN\",\n",
    "    1610612744: \"GS\",\n",
    "    1610612745: \"HOU\",\n",
    "    1610612746: \"LAL\",\n",
    "    1610612747: \"LAC\",\n",
    "    1610612748: \"MIA\",\n",
    "    1610612749: \"MIL\",\n",
    "    1610612750: \"MIN\",\n",
    "    1610612751: \"BKN\",\n",
    "    1610612752: \"NY\",\n",
    "    1610612753: \"ORL\",\n",
    "    1610612754: \"IND\",\n",
    "    1610612755: \"PHI\",\n",
    "    1610612756: \"PHX\",\n",
    "    1610612757: \"POR\",\n",
    "    1610612758: \"SAC\",\n",
    "    1610612759: \"SAS\",\n",
    "    1610612760: \"OKC\",\n",
    "    1610612761: \"TOR\",\n",
    "    1610612762: \"UTA\",\n",
    "    1610612763: \"MEM\",\n",
    "    1610612764: \"WAS\",\n",
    "    1610612765: \"DET\",\n",
    "    1610612766: \"CHA\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6f1af64-b548-47df-913d-7fe961c3dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort both Dfs by date \n",
    "# Ensure we process games only up to 12/1/2024\n",
    "season_24['GAME_DATE_EST'] = pd.to_datetime(season_24['GAME_DATE_EST'])\n",
    "end_date = datetime(2024, 12, 1)\n",
    "season_24 = season_24[season_24['GAME_DATE_EST'] <= end_date]\n",
    "season_24['TEAM_ABBREVIATION'] = season_24['TEAM_ID'].map(TEAM_CITY_ABBREVIATIONS)\n",
    "\n",
    "# Convert the 'Date' in odds data to datetime format\n",
    "season_odds_24['Date'] = pd.to_datetime(season_odds_24['Date'], format='%d-%b-%y')\n",
    "\n",
    "season_odds_24 = season_odds_24.sort_values(by='Date')\n",
    "\n",
    "# Convert the 'GAME_DATE_EST' in season stats to datetime format\n",
    "season_24['GAME_DATE_EST'] = pd.to_datetime(season_24['GAME_DATE_EST'])\n",
    "season_24 = season_24.sort_values(by='GAME_DATE_EST')\n",
    "\n",
    "features = pd.read_csv('data_generation/output_data/spearman_corr_features.csv')\n",
    "\n",
    "features_columns = features['Feature'].tolist()\n",
    "\n",
    "existing_features = [feature for feature in features_columns if feature in season_24.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f3f4594-2030-4e58-b3c4-e92f919471a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing games\n"
     ]
    }
   ],
   "source": [
    "merged_data = []\n",
    "\n",
    "# Iterate through each unique game date\n",
    "for game_date in season_odds_24['Date'].unique():\n",
    "    day_odds = season_odds_24[season_odds_24['Date'] == game_date]\n",
    "\n",
    "    # Filter games that exist in the 2024 Seasons Data\n",
    "    day_games = season_24[season_24['GAME_DATE_EST'] == game_date]\n",
    "\n",
    "    for _, game in day_odds.iterrows():\n",
    "        # Get HOME and AWAY stats\n",
    "        home_stats = day_games[day_games['TEAM_ABBREVIATION'] == game['Home']]\n",
    "        away_stats = day_games[day_games['TEAM_ABBREVIATION'] == game['Away']]\n",
    "\n",
    "        # Check to see if both teams are found\n",
    "        if not home_stats.empty and not away_stats.empty:\n",
    "            # Filter stats to include only relevant features\n",
    "            home_filtered_stats = home_stats.iloc[0][existing_features].to_dict()\n",
    "            away_filtered_stats = away_stats.iloc[0][existing_features].to_dict()\n",
    "\n",
    "            # Predict points for each team\n",
    "            home_features_df = pd.DataFrame([home_filtered_stats])[existing_features]\n",
    "            away_features_df = pd.DataFrame([away_filtered_stats])[existing_features]\n",
    "\n",
    "            home_predicted_points = rf.predict(home_features_df)\n",
    "            away_predicted_points = rf.predict(away_features_df)\n",
    "\n",
    "            predicted_spread = home_predicted_points - away_predicted_points\n",
    "\n",
    "            # Append game entry to merged_data\n",
    "            merged_data.append({\n",
    "                'Game_Date': game_date,\n",
    "                'Home': game['Home'],\n",
    "                'Away': game['Away'],\n",
    "                'Home_Stats': home_filtered_stats,\n",
    "                'Away_Stats': away_filtered_stats,\n",
    "                'Home_Predicted_Points': home_predicted_points,\n",
    "                'Away_Predicted_Points': away_predicted_points,\n",
    "                'Predicted_Spread': predicted_spread,\n",
    "                'Odds': game.to_dict()\n",
    "            })\n",
    "\n",
    "print(f\"Finished processing games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1266b3a-c48b-4915-8d07-d1cb358dc911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing games for 2024-10-22 00:00:00\n",
      "Finished processing 2024-10-22 00:00:00\n",
      "Processing games for 2024-10-23 00:00:00\n",
      "Finished processing 2024-10-23 00:00:00\n",
      "Processing games for 2024-10-24 00:00:00\n",
      "Finished processing 2024-10-24 00:00:00\n",
      "Processing games for 2024-10-25 00:00:00\n",
      "Finished processing 2024-10-25 00:00:00\n",
      "Processing games for 2024-10-26 00:00:00\n",
      "Finished processing 2024-10-26 00:00:00\n",
      "Processing games for 2024-10-27 00:00:00\n",
      "Finished processing 2024-10-27 00:00:00\n",
      "Processing games for 2024-10-28 00:00:00\n",
      "Finished processing 2024-10-28 00:00:00\n",
      "Processing games for 2024-10-29 00:00:00\n",
      "Finished processing 2024-10-29 00:00:00\n",
      "Processing games for 2024-10-30 00:00:00\n",
      "Finished processing 2024-10-30 00:00:00\n",
      "Processing games for 2024-10-31 00:00:00\n",
      "Finished processing 2024-10-31 00:00:00\n",
      "Processing games for 2024-11-01 00:00:00\n",
      "Finished processing 2024-11-01 00:00:00\n",
      "Processing games for 2024-11-02 00:00:00\n",
      "Finished processing 2024-11-02 00:00:00\n",
      "Processing games for 2024-11-03 00:00:00\n",
      "Finished processing 2024-11-03 00:00:00\n",
      "Processing games for 2024-11-04 00:00:00\n",
      "Finished processing 2024-11-04 00:00:00\n",
      "Processing games for 2024-11-06 00:00:00\n",
      "Finished processing 2024-11-06 00:00:00\n",
      "Processing games for 2024-11-07 00:00:00\n",
      "Finished processing 2024-11-07 00:00:00\n",
      "Processing games for 2024-11-09 00:00:00\n",
      "Finished processing 2024-11-09 00:00:00\n",
      "Processing games for 2024-11-10 00:00:00\n",
      "Finished processing 2024-11-10 00:00:00\n",
      "Processing games for 2024-11-11 00:00:00\n",
      "Finished processing 2024-11-11 00:00:00\n",
      "Processing games for 2024-11-12 00:00:00\n",
      "Finished processing 2024-11-12 00:00:00\n",
      "Processing games for 2024-11-13 00:00:00\n",
      "Finished processing 2024-11-13 00:00:00\n",
      "Processing games for 2024-11-14 00:00:00\n",
      "Finished processing 2024-11-14 00:00:00\n",
      "Processing games for 2024-11-15 00:00:00\n",
      "Finished processing 2024-11-15 00:00:00\n",
      "Processing games for 2024-11-16 00:00:00\n",
      "Finished processing 2024-11-16 00:00:00\n",
      "Processing games for 2024-11-17 00:00:00\n",
      "Finished processing 2024-11-17 00:00:00\n",
      "Processing games for 2024-11-18 00:00:00\n",
      "Finished processing 2024-11-18 00:00:00\n",
      "Processing games for 2024-11-19 00:00:00\n",
      "Finished processing 2024-11-19 00:00:00\n",
      "Processing games for 2024-11-20 00:00:00\n",
      "Finished processing 2024-11-20 00:00:00\n",
      "Processing games for 2024-11-21 00:00:00\n",
      "Finished processing 2024-11-21 00:00:00\n",
      "Processing games for 2024-11-22 00:00:00\n",
      "Finished processing 2024-11-22 00:00:00\n",
      "Processing games for 2024-11-23 00:00:00\n",
      "Finished processing 2024-11-23 00:00:00\n",
      "Processing games for 2024-11-24 00:00:00\n",
      "Finished processing 2024-11-24 00:00:00\n",
      "Processing games for 2024-11-25 00:00:00\n",
      "Finished processing 2024-11-25 00:00:00\n",
      "Processing games for 2024-11-26 00:00:00\n",
      "Finished processing 2024-11-26 00:00:00\n",
      "Processing games for 2024-11-27 00:00:00\n",
      "Finished processing 2024-11-27 00:00:00\n",
      "Processing games for 2024-11-29 00:00:00\n",
      "Finished processing 2024-11-29 00:00:00\n",
      "Processing games for 2024-11-30 00:00:00\n",
      "Finished processing 2024-11-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "final_results = []\n",
    "\n",
    "unique_dates = sorted({entry['Game_Date'] for entry in merged_data})\n",
    "\n",
    "# Iterate through each game date\n",
    "for game_date in unique_dates:\n",
    "    print(f\"Processing games for {game_date}\")\n",
    "\n",
    "    # Filter games for the current day\n",
    "    day_games = [entry for entry in merged_data if entry[\"Game_Date\"] == game_date]\n",
    "\n",
    "    # Prepare training data for the current day\n",
    "    X_train = pd.DataFrame(\n",
    "        [game['Home_Stats'] for game in day_games] +\n",
    "        [game['Away_Stats'] for game in day_games]\n",
    "    )[existing_features].values\n",
    "\n",
    "    y_train = pd.DataFrame([\n",
    "        {'Actual_Points': game['Odds']['Score.1']} for game in day_games\n",
    "    ] + [\n",
    "        {'Actual_Points': game['Odds']['Score']} for game in day_games\n",
    "    ]).values\n",
    "\n",
    "    # Fine-tune the model with the day's data\n",
    "    rf.fit(X_train, y_train.flatten())\n",
    "\n",
    "    # Append games for the day to final results\n",
    "    final_results.extend(day_games)\n",
    "\n",
    "    print(f\"Finished processing {game_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b09f11ce-ee9b-41d4-9af6-7c38afcf4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert merged_data to a DataFrame\n",
    "merged_df = pd.DataFrame(merged_data)\n",
    "\n",
    "# Save to a CSV file\n",
    "merged_df.to_csv(\"2024_predictions_by_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36387a2-d51d-4675-8a0b-f030374f7d7a",
   "metadata": {},
   "source": [
    "### Run Analytics on the 2024 Predictions Compared to 2024 Season Actual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65a4a7cb-cdf6-485d-a1f3-15b0bc1f9e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Statistics for Predictions:\n",
      "Mean Absolute Error (Points): 8.05\n",
      "Mean Squared Error (Points): 96.81\n",
      "Root Mean Squared Error (Points): 9.84\n",
      "\n",
      "Spread Analysis:\n",
      "Mean Absolute Error (Spread): 10.81\n",
      "\n",
      "ATS Results:\n",
      "Total Games: 207\n",
      "ATS Hits: 139\n",
      "ATS %: 67.15%\n"
     ]
    }
   ],
   "source": [
    "prediction_errors = []\n",
    "spread_errors = []\n",
    "ats_hits = 0\n",
    "total_games = len(merged_data)\n",
    "\n",
    "for game in merged_data:\n",
    "    # Predicted vs actual points \n",
    "    home_error = abs(game['Home_Predicted_Points'] - game['Odds']['Score.1'])\n",
    "    away_error = abs(game['Away_Predicted_Points'] - game['Odds']['Score'])\n",
    "    prediction_errors.extend([home_error, away_error])\n",
    "\n",
    "    # Spread analysis\n",
    "    calculated_spread = game['Predicted_Spread']\n",
    "    actual_spread = game['Odds']['Home Spread']\n",
    "    spread_error = abs(calculated_spread - actual_spread)\n",
    "    spread_errors.append(spread_error)\n",
    "\n",
    "    # ATS Calculations\n",
    "    actual_result_spread = game['Odds']['Score.1'] - game['Odds']['Score']\n",
    "    if (calculated_spread > 0 and actual_result_spread > actual_spread) or (calculated_spread < 0 and actual_result_spread < actual_spread):\n",
    "            ats_hits += 1\n",
    "\n",
    "# General performance stats\n",
    "prediction_mae = np.mean(prediction_errors)\n",
    "prediction_mse = np.mean(np.square(prediction_errors))\n",
    "prediction_rmse = np.sqrt(prediction_mse)\n",
    "\n",
    "spread_mae = np.mean(spread_errors)\n",
    "\n",
    "ats_percentage = (ats_hits/total_games) * 100\n",
    "\n",
    "# Display Results\n",
    "print(\"General Statistics for Predictions:\")\n",
    "print(f\"Mean Absolute Error (Points): {prediction_mae:.2f}\")\n",
    "print(f\"Mean Squared Error (Points): {prediction_mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (Points): {prediction_rmse:.2f}\")\n",
    "\n",
    "print(\"\\nSpread Analysis:\")\n",
    "print(f\"Mean Absolute Error (Spread): {spread_mae:.2f}\")\n",
    "\n",
    "print(\"\\nATS Results:\")\n",
    "print(f\"Total Games: {total_games}\")\n",
    "print(f\"ATS Hits: {ats_hits}\")\n",
    "print(f\"ATS %: {ats_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77cac1-8c3c-49aa-8108-4bec1be25b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
